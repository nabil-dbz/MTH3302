{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTH3302 : Méthodes probabilistes et statistiques pour l'I.A.\n",
    "\n",
    "Jonathan Jalbert<br/>\n",
    "Professeur agrégé au Département de mathématiques et de génie industriel<br/>\n",
    "Polytechnique Montréal<br/>\n",
    "\n",
    "Les images proviennent du jeu de données publiques *The Extended Yale Face Database B* disponible sur le site http://vision.ucsd.edu/~iskwak/ExtYaleDatabase/ExtYaleB.html.\n",
    "\n",
    "\n",
    "## TD6 : Reconnaissance faciale avec l'analyse en composantes principales\n",
    "\n",
    "\n",
    "Nous utiliserons des images récupérées de la base de données publique de Yale$^{(1)}$ que vous pouvez trouver sur Moodle. Nous avons choisi les 2 ensembles de telle sorte que l'ensemble de test contienne à la fois des images déjà vues et d'autres tout-à-fait nouvelles. L'objectif final est de mesurer la performance de notre algorithme en comptant le nombre d'exemples bien classifiés.\n",
    "\n",
    "Plusieurs librairies que nous n'utilisons pas régulièrement dans le cours sont nécessaire. Exécutez la prochaine cellule de code pour installer ces librairies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pkg\n",
    "Pkg.add([\"Images\",\"Netpbm\",\"ImageMagick\",\"Colors\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librairies standards du cours\n",
    "using Statistics, LinearAlgebra, Gadfly, DataFrames\n",
    "\n",
    "# Librairie pour le traitement des images\n",
    "using Images, Netpbm, ImageMagick, Colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 1. Chargement des images d'entraînement\n",
    "___\n",
    "\n",
    "Les images d'entraînement sont contenues dans le dossier *Train* du jeu de données que vous pouvez récupérer sur Moodle. L'ensemble d'entraînement est constitué de 784 images provenant de 28 personnes différente, soit de 28 images par personne.\n",
    "\n",
    "Les images sont des visages déjà correctement alignés, ce qui nous permet de nous concentrer directemement sur la reconnaissance des visages.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération de tous les noms de fichiers de l'échantillon d'entraînement\n",
    "file = readdir(\"Train\")\n",
    "trainFileName = [\"Train/\"*file[i] for i=1:length(file)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage des 8 photos de la première personne\n",
    "load.(trainFileName[1:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage des 8 photos de la huitième personne\n",
    "load.(trainFileName[29:36])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    imgrayconvert(imageFileName ; columnStack=true ; T=Int64)\n",
    "\n",
    "Conversion en intensité de gris de l'image du fichier `imageFileName`.\n",
    "\n",
    "### Arguments\n",
    "- `imageFileName::string` : le nom du fichier de l'image\n",
    "- `columnStack::bool=true` : Si `true`, l'image est renvoyée comme un vecteur colonne (option par défaut) \n",
    "                             sinon la fonction renvoie la matrice des niveaux de gris.\n",
    "- `T::DataType=Int64` : Type des éléments de la matrice (Int64 par défaut).\n",
    "\n",
    "### Details\n",
    " \n",
    "La fonction retourne la matrice ou le vecteur colonne des niveaux de gris.\n",
    " \n",
    "### Examples\n",
    "\n",
    "\\```\n",
    " julia> imgrayconvert(imageFileName)\n",
    " julia> imgrayconvert(imageFileName ; columnStack=false)\n",
    " julia> imgrayconvert(imageFileName ; T=Float64)\n",
    "\\```\n",
    "\n",
    "\"\"\"\n",
    "function imgrayconvert(imageFileName::String ; columnStack::Bool=true)\n",
    "    im = load(imageFileName)\n",
    "    X = Float64.(im)\n",
    "    if columnStack\n",
    "        Y = X[:]\n",
    "    else\n",
    "        Y = X\n",
    "    end\n",
    "    return Y\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    imshow(X), imshow(X, im_size)\n",
    "\n",
    "Affiche une matrice ou un vecteur en une image composée de niveau de gris.\n",
    "\n",
    "### Arguments\n",
    "- `X::Array{Real}` : Une matrice ou un vecteur colonne à afficher.\n",
    "- `im_size::Tuple{Int64,Int64}` : Un tuple de Int64 indicant la taille de l'image. \n",
    "\n",
    "\n",
    "### Details\n",
    "\n",
    "L'argument `im_size` n'est nécessaire que si un vecteur colonne est envoyé comme image.\n",
    "\n",
    "L'échelle des niveaux de gris est ajustée en fonction des valeurs contenues dans X.\n",
    " \n",
    "### Examples\n",
    "\n",
    "\\```\n",
    " julia> imshow(X)\n",
    " julia> imshow(X, (m₁, m₂))\n",
    "\\```\n",
    "\n",
    "\"\"\"\n",
    "function imshow(X::Array{<:Real,1}, im_size::Tuple{Int64,Int64})\n",
    "    \n",
    "    # scale the eigenvector for display on grayscale\n",
    "    m = minimum(X)\n",
    "    M = maximum(X)\n",
    "    \n",
    "    Z = (X .- m) / (M-m)\n",
    "    \n",
    "    Z = reshape(Z, im_size)\n",
    "\n",
    "    Gray.(Z)\n",
    "    \n",
    "end\n",
    "\n",
    "function imshow(X::Array{<:Real,2})\n",
    "    \n",
    "    # scale the eigenvector for display on grayscale\n",
    "    m = minimum(X)\n",
    "    M = maximum(X)\n",
    "    \n",
    "    Z = (X .- m) / (M-m)\n",
    "    \n",
    "    Gray.(Z)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des images de l'ensemble d'entrainement. Chaque image correspond à une ligne de la matrice X, \n",
    "# chaque pixel à une colonne.\n",
    "\n",
    "n = length(trainFileName)\n",
    "\n",
    "im = imgrayconvert(trainFileName[1],columnStack=false)\n",
    "m₁, m₂ = size(im)\n",
    "m = m₁ * m₂\n",
    "\n",
    "X = Array{Float64,2}(undef,n,m)\n",
    "\n",
    "for i=1:n\n",
    "   X[i,:] = imgrayconvert(trainFileName[i], columnStack=true) \n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Analyse en composantes principales\n",
    "\n",
    "Le but de cette section est de réduire la dimension du jeu de données d'entraînement. Nous ferons donc une décomposition en valeurs singulières de l'ensemble d'entraînement.\n",
    "\n",
    "Les étapes sont les suivantes :\n",
    "1. Centrer chacune des lignes de la matrice des visages d'entraînement pour obtenir la matrice $Z$.\n",
    "2. Effectuer une décomposition en valeurs singulières de $Z$.\n",
    "3. Choisir le nombre de composantes principales requises $k$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Centrer les images de l'ensemble d'entraînement\n",
    "\n",
    "### a) Calculez le visage moyen $\\bar{X}$ en faisait une moyenne de tous les visages pour chacun des pixels. Affichez le visage moyen avec la fonction `imshow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Calculer la matrice $Z$ centrée des visages de l'ensemble d'entraînement. Ensuite, afficher la différence entre le premier visage  et le visage moyen avec la fonction `imshow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Décomposition en valeurs singulières de $Z$.\n",
    "\n",
    "### a) Obtenez les matrices $U$ et $V$ ainsi que les valeurs singulières à l'aide de la fonction `svd` et/ou de la fonction `svdvals`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Affichez les premiers vecteurs singuliers de $V$ avec la fonction `imshow`. \n",
    "\n",
    "Ces composantes représentent les modes de plus grande variabilité. Dans la reconnaissance faciale, elles sont appelées les *eigenfaces*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Choix du nombre $k$ de vecteurs singuliers à utiliser\n",
    "\n",
    "### a) Tracez un graphique permettant de voir le pourcentage de la variance totale retenue en fonction du nombre de vecteur singuliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Calculez le pourcentage de la variance récupérée en utilisant 10, 50 et 70 composantes principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Approximation d'une image à l'aide des vecteurs singuliers\n",
    "\n",
    "Soit $k$ le nombre de vecteurs singuliers retenus. Nous allons approximer le visage $\\mathbf{z}_i$ à l'aide des $k$ premières vecteurs singuliers. \n",
    "\n",
    "Dénotons par $V_k$ la matrice des $k$ premiers vecteurs singuliers de $V$. On cherche à trouver la combinaison linéaire des $k$ vecteurs qui approxime le visage $\\mathbf{z}_i$ :\n",
    "\n",
    "$$ \\mathbf{Z}_i = V_k \\mathbf{w} + \\varepsilon ; $$\n",
    "\n",
    "où $\\mathbf{w}$ correspond au vecteur des poids de la combinaison linéaire et $\\varepsilon$ correspond à l'erreur que l'on fait. L'erreur serait nulle si on utilisait tous les vecteurs singuliers.\n",
    "\n",
    "On se retrouve donc dans un problème de régression où la variable d'intérêt est l'image du visage et où les variables explicatives sont les vecteur singuliers $V_k$. Pour trouver les coefficients de régression $\\mathbf{w}$, il suffit de procéder comme au chapitre 2 :\n",
    "\n",
    "$$ \\mathbf{\\hat{w}} = (V_k^\\top V_k)^{-1} V_k^\\top \\mathbf{z}_i . $$\n",
    "\n",
    "Or, puisque la matrice des vecteurs singuliers est orthonormales, la dernière équation se simplifie à l'expression suivante :\n",
    "\n",
    "$$ \\mathbf{\\hat{w}} = V_k^\\top \\mathbf{z}_i . $$\n",
    "\n",
    "Le visage $\\mathbf{z}_i$ projeté dans les k premières composantes principales, dénoté par $\\mathbf{\\hat{z}}_i$,  est obtenue avec l'équation suivante :\n",
    "\n",
    "$$ \\mathbf{\\hat{z}}_i = V_k \\mathbf{\\hat{w}}.$$\n",
    "\n",
    "\n",
    "\n",
    "**Remarque :** On pourrait être de tenté de calculer la projection du visage en une seule étape, en remplaçant $\\mathbf{w}$ par son expression :\n",
    "\n",
    "$$ \\mathbf{\\hat{z}}_i = V_k \\mathbf{\\hat{w}} = V_k V_k^\\top \\mathbf{z}^\\top_i.$$\n",
    "\n",
    "La matrice $V_k V_k^\\top$ correspond à une matrice de projection dans l'espace des $k$ premières composantes principales. Il faut cependant traiter le produit matricielle $V_k V_k^\\top$ avec attention pour obtenir des résultats précis et rapides. Il est souvent plus judicieux de procéder en deux étapes :\n",
    "1. Calculer les poids $\\mathbf{\\hat{w}}$.\n",
    "2. Calculer la projection de l'image $\\mathbf{\\hat{z}}_i^\\top = V_k \\mathbf{\\hat{w}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Approximation du visage 1 avec les 10 premiers vecteurs singuliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "k = 10\n",
    "\n",
    "Vk = V[:,1:k]\n",
    "zᵢ = Z[i,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Calculez les coefficients ŵ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Calculez l'approximation du visage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Affichez le visage original et son approximation\n",
    "\n",
    "Vous pouvez ajouter le visage moyen pour une meilleure interprétation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Approximation du visage 1 avec les 50 premières vecteurs singuliers\n",
    "\n",
    "Reprenez les étapes précédentes mais cette fois en utilisant les 50 premiers vecteurs singuliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "k = 50\n",
    "\n",
    "Vk = V[:,1:k]\n",
    "zᵢ = Z[i,:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Approximation du visage 1 avec les 70 premières vecteurs singuliers\n",
    "\n",
    "Reprenez les étapes précédentes mais cette fois en utilisant les 70 premiers vecteurs singuliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "k = 70\n",
    "\n",
    "Vk = V[:,1:k]\n",
    "zᵢ = Z[i,:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Approximation du visage 29 avec les 50 premières vecteurs singuliers\n",
    "\n",
    "Reprenez les étapes précédentes mais cette fois avec le visage 29."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 29\n",
    "k = 50\n",
    "\n",
    "Vk = V[:,1:k]\n",
    "zᵢ = Z[i,:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Reconnaissance faciale\n",
    "\n",
    "\n",
    "L'idée de la reconnaissance faciale consiste à comparer le vecteur des coefficient $\\mathbf{\\hat{w}}$ de l'image à reconnaître avec les vecteurs poids des images de l'ensemble d'entraînement. C'est une comparaison assez facile à faire car ce vecteur est de dimension raisonnable comparativement aux images originales. En effet, dans notre cas, si on prend 50 vecteurs singuliers, le vecteur des coefficient est un vecteur colonne de taille 50. On peut donc résumer toutes les images par leur vecteur des coefficients de taille 50. \n",
    "\n",
    "Pour savoir, si une nouvelle image représente une personne présente dans l'ensemble d'entraînement, on n'a qu'à comparer son vecteur des coefficients avec chacun des vecteurs des coefficients de l'ensemble d'entraînement. Cette comparaison est facile, rapide et efficace car les vecteurs sont de tailles raisonnables. Si la différence entre les vecteurs est très grande, cela suggère que la personne est inconnue de l'ensemble d'entraînement. Si la différence est petite avec un des vecteurs de coefficients, cela suggère qu'il s'agit de la même personne. Le seuil doit être ajusté avec de la validation croisée.\n",
    "\n",
    "Dans cette section, vous déciderez si une nouvelle image de l'ensemble test représente un personne connue ou inconnue. Vous le ferez en complétant les étapes suivantes :\n",
    "\n",
    "1. Calculez les poids de toutes les images de l'ensemble d'entraînement.\n",
    "2. Calculez les poids de l'image de test.\n",
    "3. Calculez la distance entre les vecteurs poids des images d'entraînement et celui de l'image de test.\n",
    "4. Identifiez l'image de l'ensemble d'entraînement la plus proche de l'image de test.\n",
    "5. Décidez si le visage se retrouve dans l'échantillon d'entraînement ou s'il est inconnu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Calculez les poids de toutes les images de l'ensemble d'entraînement\n",
    "\n",
    "Prenez pour l'instant $k = 50$ composantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 50\n",
    "Vk = V[:,1:k]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Calculez les poids de l'image de test\n",
    "\n",
    "Prenons d'abord la première image de l'échantillon de test. Il faut charger l'image, retirer le visage moyen et calculer les poids.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération de tous les noms de fichiers de l'échantillon d'entraînement\n",
    "file = readdir(\"Test\")\n",
    "testFileName = [\"Test/\"*file[i] for i=1:length(file)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion de l'image de test en intensités de gris et retrait du visage moyen\n",
    "\n",
    "j = 1  # j^e image de l'échantillon de test\n",
    "\n",
    "y = imgrayconvert(testFileName[j]) - X̄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Calculez la distance euclidienne entre les vecteurs poids des images d'entraînement et celui de l'image de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Identifiez l'image de l'ensemble d'entraînement la plus proche de l'image de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Décidez si le visage se retrouve dans l'échantillon d'entraînement ou s'il est inconnu.\n",
    "\n",
    "Si la distance minimale entre les poids des images d'entraînement et des poids de l'image de test, alors on statuera que le visage est inconnu. Il faut définir cependant définir ce seuil à l'aide de la validation croisée. Tentez d'utiliser le seuil de (3500)^2 et refaites les étapes du numéro 4 avec les autres images de l'ensemble de test.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Récupération des noms des personnes sur les images de l'ensemble d'entraînement\n",
    "# ind1 = findfirst(isequal('/'),trainFileName[1])\n",
    "# ind2 = findfirst(isequal('_'),trainFileName[1])\n",
    "# trainPerson = [trainFileName[i][ind1+1:ind2-1] for i=1:length(trainFileName)];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.6.2",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
